## 亿级流量关注点

### 1.存储与计算

### 2.高容错

### 3.每秒数10万查询高并发

### 4.全链路高可用99.99%



## 1.亿级流量架构存储与计算架构演变

1.第一版本

[第一版本架构](../image/version1.jpg)

- 问题
- 1.业务发展，每天的数据达到亿级别，存储是个大问题
- 2.由于大表导致的查询缓慢，查询可能导致mysql宕机

- 3.如何解决

2.第二版本(离线与实时拆分)

- 1.思路:将昨天及昨天以前的数据在大数据中存储(分布式存储)，进行离线存储与离线计算
- 2.思路:将今天的数据进行实时计算

[第二版本架构](../image/version2.jpg)

- 问题
- 1.业务发展，实时计算存储数据达到亿级别
- 2.由于大表导致的查询缓慢，查询可能导致mysql宕机
- 3.单台数据库服务器无法存储下当日的数据

- 3.如何解决


3.第三版本(实时数据每天达到亿级别)

- 1.思路:分库分表解决数据当日存储的瓶颈问题

- 问题

- 1.每一个数据库服务又读又写，导致数据库的cpu负载和io负载非常高

```
因为在此时写数据库的每秒并发已经达到几千了，同时还频繁的运行那种超大SQL来查询数据，数据库服务器的CPU运算会极其的繁忙。
```

- 2.如何解决
- 3.读写分离

[第三版本架构](../image/version3.jpg)


4.第四版本(实时数据查询与写并存导致数据库服务压力过大)

- 1.思路:引入读写分离解决

- 问题

- 1.业务查询(大sql),要求秒级响应

- 2.如何解决(滑动窗口解决)


[第四版本架构](../image/version4.jpg)



5.第五版本(数据查询达到秒级别响应)

- 1.思路:引入滑动窗口

```
在数据库binlog采集中间件采集的过程中，要将数据的变更切割为一个一个的滑动时间窗口，每个滑动时间窗口为几秒钟，对每个窗口内的数据打上那个窗口的标签

同时需要维护一份滑动时间窗口的索引数据，包括每个分片的数据在哪个窗口里，每个窗口的数据的一些具体的索引信息和状态

接着数据平台中的核心计算引擎，不再是每隔几十秒就运行大量SQL对当天所有的数据全部计算一遍了，而是对一个接一个的滑动时间窗口，根据窗口标签提取出那个窗口内的数据进行计算，计算的仅仅是最近一个滑动时间窗口内的数据

接着对这个滑动时间窗口内的数据，可能最多就千条左右吧，运行所有的复杂SQL计算出这个滑动时间窗口内的报表数据，然后将这个窗口数据计算出的结果，与之前计算出来的其他窗口内的计算结果进行合并，最后放入MySQL中的报表内

```

- 问题


[第五版本架构](../image/version5.jpg)


6.第6版(离线数据计算比较耗时，数据量大)


-问题

```
关键问题就在于，离线计算链路，每天都是导入全量数据来进行计算，这就很坑了
```

- 解决方法

```
主要就是全量计算转增量计算：每天数据在导入hadoop之后，都会针对数据的业务时间戳来分析和提取出来每天变更过的增量数据，将这些增量数据放入独立的增量数据表中。

同时需要根据具体的业务需求，自动分析数据计算的基础血缘关系，有可能增量数据需要与部分全量数据混合才能完成计算，此时可能会提取部分全量历史数据，合并完成计算。计算完成之后，将计算结果与历史计算结果进行合并。
```

[第六版本架构](../image/version6.jpg)


## 2.亿级流量架构高容错分布式演变

- 1.单点故障

### 1.高可用架构(active-standby架构)

- 解决思路:依据zookeeper的高可用架构，部署2台以上的数据平台架构，实现自动感知，适时进行动态的主备切换
- https://blog.csdn.net/JSON_ZJS/article/details/80686460

[第七版本架构](../image/version7.jpg)


- 2.时间窗口内CPU过高，计算数据量过大(引入分布式 master-slave)

### 1.Master-Slave架构的分布式计算系统

````
数据平台系统其实最核心的任务就是对一个一个的时间窗口中的数据进行计算，但是随着每天的日增数据量越来越多，每个时间窗口内的数据量也会越来越大，同时会导致数据平台系统的计算负载越来越高。

在线上生产环境表现出来的情况就是，数据平台系统部署机器的CPU负载越来越高，高峰期很容易会100%，机器压力较大
````

- 解决思路:我们将数据平台系统彻底重构和设计为一套分布式的计算系统，将任务调度与任务计算两个职责进行分离，有一个专门的Master节点负责读取切分好的数据分片（也就是所谓的时间窗口，一个窗口就是一个数据分片），然后将各个数据分片的计算任务分发给多个Slave节点。
        Slave节点的任务就是专门接收一个一个的计算任务，每个计算任务就是对一个数据分片执行一个几百行到上千行的复杂SQL语句来产出对应的数据分析结果。
        
[第八版本架构](../image/version8.jpg)